{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_als\n",
    "import data_prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = data_prepro.loadData('datasets/data_tr_city.csv','datasets/data_ts_city.csv',trainYearRange1=2019,trainYearRange2=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([17558, 21595, 25626], dtype='int64')\n",
      "index                  0\n",
      "datetime               0\n",
      "구미 혁신도시배수지 유출유량 적산차    2\n",
      "year                   0\n",
      "month                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = data_prepro.outlierDataToNan(train,low=True,high=False,thres=10.0)\n",
    "# train = data_prepro.fillZero(train)\n",
    "train = data_prepro.fillnaBehind(train)\n",
    "train = data_prepro.fillprevValue(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = data_prepro.XDataToXAndYSeq(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test = data_prepro.XDataToXAndYSeq(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17519, 1, 24), (17519, 1))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,24,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17519, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(-1,24,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[114.],\n",
       "        [ 83.],\n",
       "        [ 68.],\n",
       "        ...,\n",
       "        [431.],\n",
       "        [610.],\n",
       "        [417.]],\n",
       "\n",
       "       [[ 83.],\n",
       "        [ 68.],\n",
       "        [ 90.],\n",
       "        ...,\n",
       "        [610.],\n",
       "        [417.],\n",
       "        [224.]],\n",
       "\n",
       "       [[ 68.],\n",
       "        [ 90.],\n",
       "        [112.],\n",
       "        ...,\n",
       "        [417.],\n",
       "        [224.],\n",
       "        [116.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[305.],\n",
       "        [362.],\n",
       "        [207.],\n",
       "        ...,\n",
       "        [473.],\n",
       "        [305.],\n",
       "        [328.]],\n",
       "\n",
       "       [[362.],\n",
       "        [207.],\n",
       "        [133.],\n",
       "        ...,\n",
       "        [305.],\n",
       "        [328.],\n",
       "        [347.]],\n",
       "\n",
       "       [[207.],\n",
       "        [133.],\n",
       "        [153.],\n",
       "        ...,\n",
       "        [328.],\n",
       "        [347.],\n",
       "        [335.]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116.],\n",
       "       [ 49.],\n",
       "       [ 31.],\n",
       "       ...,\n",
       "       [335.],\n",
       "       [141.],\n",
       "       [112.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 84.],\n",
       "       [ 87.],\n",
       "       [ 84.],\n",
       "       ...,\n",
       "       [396.],\n",
       "       [350.],\n",
       "       [197.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([17519, 24, 1]) torch.Size([17519, 1])\n",
      "Testing Shape torch.Size([8399, 24, 1]) torch.Size([8399, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(x_train))\n",
    "X_test_tensors = Variable(torch.Tensor(x_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test))\n",
    "\n",
    "X_train_tensors_final = torch.reshape(X_train_tensors,   X_train_tensors.shape)\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  X_test_tensors.shape) \n",
    "\n",
    "print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla M40 24GB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # device\n",
    "except:\n",
    "    device = \"cpu\"\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 20])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "m = weight_norm(nn.Linear(20, 40), name='weight')\n",
    "m # Linear(in_features=20, out_features=40, bias=True)\n",
    "m.weight_g.size() # torch.Size([40, 1])\n",
    "m.weight_v.size() # torch.Size([40, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Inputs have to have dimension (N, C_in, L_in)\"\"\"\n",
    "        y1 = self.tcn(inputs)  # input should have dimension (N, C, L)\n",
    "        o = self.linear(y1[:, :, -1])\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30000 #1000 epochs\n",
    "learning_rate = 0.01 #0.001 lr\n",
    "\n",
    "kernel_size = 5\n",
    "stride = 1\n",
    "dilation = 1\n",
    "padding=2\n",
    "dropout=0.2\n",
    "input_size = 24 #number of features\n",
    "hidden_size = 256 #number of features in hidden state\n",
    "num_channels = [512,512,256] #number of stacked lstm layers\n",
    "\n",
    "output_size = 1 #number of output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn = TCN(input_size, output_size, num_channels, kernel_size, dropout).to(device)\n",
    "\n",
    "loss_function = torch.nn.L1Loss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(tcn.parameters(), lr=learning_rate)  # adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 250.14949, test data loss 259.26007080078125\n",
      "Epoch: 20, loss: 250.83366, test data loss 259.98541259765625\n",
      "Epoch: 40, loss: 225.11330, test data loss 232.98731994628906\n",
      "Epoch: 60, loss: 141.45525, test data loss 143.91183471679688\n",
      "Epoch: 80, loss: 139.98494, test data loss 141.7073516845703\n",
      "Epoch: 100, loss: 140.06993, test data loss 141.88394165039062\n",
      "Epoch: 120, loss: 139.99059, test data loss 141.3670654296875\n",
      "Epoch: 140, loss: 140.14348, test data loss 141.63641357421875\n",
      "Epoch: 160, loss: 139.58258, test data loss 141.60183715820312\n",
      "Epoch: 180, loss: 139.77516, test data loss 141.1579132080078\n",
      "Epoch: 200, loss: 139.39783, test data loss 141.2375030517578\n",
      "Epoch: 220, loss: 139.25903, test data loss 140.7466278076172\n",
      "Epoch: 240, loss: 139.26355, test data loss 140.48175048828125\n",
      "Epoch: 260, loss: 139.00117, test data loss 140.15478515625\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    outputs = tcn.forward(X_train_tensors_final.to(device)) #forward pass\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = loss_function(outputs, y_train_tensors.to(device))\n",
    "\n",
    "    if epoch%20 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()),end=', ')\n",
    "        outputs = tcn.forward(X_test_tensors_final.to(device)) #forward pass\n",
    "        test_loss = loss_function(outputs, y_test_tensors.to(device))\n",
    "        # loss.backward() #calculates the loss of the loss function\n",
    "\n",
    "        print(\"test data loss\",test_loss.item())\n",
    "\n",
    "    optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "    loss.backward() #calculates the loss of the loss function\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
